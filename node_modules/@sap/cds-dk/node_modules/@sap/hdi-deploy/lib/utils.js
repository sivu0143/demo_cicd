'use strict';


const fs = require('fs');
const paths = require('./paths.js');
const strip_json_comments = require('./json-comment-stripper');
const tls = require('tls');
const log = require('./logger');
const is_hdb_client = log.getClientValue() === log.hdb;
const crypto = require('crypto');
const async = require('async');
const { FileWithContent } = require('@sap/hdi');

/**
 * Remove duplicate messages - detect duplicated by their "id" property.
 *
 * @param {String[]} messages Array of messages
 * @returns {String[]} Array of messages without duplicates
 */
exports.dedupeMessagesById = function (messages) {
  const map = {};
  const dedupedMessages = [];

  const length = messages.length;

  for (let i = 0; i < length; i++) {
    const message = messages[i];
    if (!map[message.id]) {
      map[message.id] = true;
      dedupedMessages.push(message);
    }
  }

  return dedupedMessages;
};

/**
 * Read the given file. Strip comments from the file before parsing it as JSON.
 *
 * @param {String} filename File to read.
 * @returns {Object} The parsed file.
 */
exports.readJSONFile = function (filename) {
  const raw_stripped_file = strip_json_comments(fs.readFileSync(filename, 'utf8'));
  let file;

  try {
    file = JSON.parse(raw_stripped_file);
  } catch (error) {
    throw new Error(`Could not parse JSON file "${filename}": ${error}`);
  }

  return file;
};

/**
 * <a>.<b> turns into <a>"."<b>. This assumes that the outer "" will be added at a later stage.
 *
 * @param {any} name Name to quote.
 * @returns {String} Quoted name.
 */
function quote_dot (name) {
  const parts = name.split('.');
  if (parts.length > 2) {
    throw new Error(`There were multiple "." found in name "${name}". There can only be at most one ".".`);
  } else if (parts.length === 2) {
    name = `${parts[0]}"."${parts[1]}`;
  }
  return name;
}

exports.identifier = function (name) {
  // escape " inside identifiers to ""
  name = name.replace(/\"/g, '""');
  /*
   * Surround result with "..."
   */
  return `"${name}"`;
};

exports.dot_quoted_identifier = function (name) {
  // escape " inside identifiers to ""
  name = name.replace(/\"/g, '""');
  /*
   * Escape System privilege with a dot like a schema local role.
   * surround result with "..."
   */
  return `"${quote_dot(name)}"`;
};

exports.quote_dot_in_system_privilege_for_procedure = function (name) {
  const parts = name.split('.');
  if (parts.length === 2) {
    return `"${quote_dot(name)}"`;
  } else {
    return name;
  }
};

/*
 * Checks if variable is an Array.
 *
 * @param {any} variable Var to check.
 * @returns {boolean} True or false.
 */
function isArray (variable) {
  return (variable instanceof Array || Object.prototype.toString.call(variable) === '[object Array]');
}

exports.isArray = isArray;

/**
 * Checks if the given file is a hdbsynonymgrantor or hdbgrants file.
 *
 * @param {String} file File to check.
 * @returns {boolean} True if it's a grantor file.
 */
function isGrantorFile (file) {
  const ext = paths.extname(file);
  if (ext !== '') {
    return ext === '.hdbsynonymgrantor' || ext === '.hdbgrants';
  } else {
    const base = paths.basename(file);
    return base === '.hdbgrants';
  }
}
exports.isGrantorFile = isGrantorFile;

/**
 * Checks if the given file is a hdbsynonymgrantor or hdbgrants file.
 *
 * @param {String} file File to check.
 * @returns {boolean} True if it's a grantor file.
 */
function isRevokerFile (file) {
  const ext = paths.extname(file);
  if (ext !== '') {
    return ext === '.hdbrevokes';
  } else {
    const base = paths.basename(file);
    return base === '.hdbrevokes';
  }
}
exports.isRevokerFile = isRevokerFile;

/**
 * Check if the file is deployable.
 * This is used to filter out non-deployable files.
 *
 * @param {String} file File to check.
 * @returns {boolean} True if the file is deployable.
 */
function isDeployableFile (file) {
  return !isGrantorFile(file) && !isRevokerFile(file);
}

exports.isDeployableFile = isDeployableFile;

/**
 * Check if the file is a .hdbsynonymtemplate file.
 *
 * @param {String} file The name of the file
 * @returns {boolean} True if it's a .hdbsynonymtemplate file.
 */
function isSynonymTemplateFile (file) {
  return paths.extname(file) === '.hdbsynonymtemplate';
}

exports.isSynonymTemplateFile = isSynonymTemplateFile;

/**
 * Check if the file is a .hdbsynonymconfig file.
 *
 * @param {String} file The name of the file
 * @returns {boolean} True if it's a .hdbsynonymconfig file.
 */
function isSynonymConfigFile (file) {
  return paths.extname(file) === '.hdbsynonymconfig';
}

exports.isSynonymConfigFile = isSynonymConfigFile;

/**
 * Build the filename of the hdbsynonymconfig file for a given hdbsynonymtemplate file.
 *
 * @param {any} file The name of the hdbsynonymtemplate
 * @returns {String} The hdbsynonymconfig filename.
 */
exports.rename_synonymtemplate_to_config = function (file) {
  return paths.serverPath(paths.join(paths.dirname(file), `${paths.basename(file, '.hdbsynonymtemplate')}.hdbsynonymconfig`));
};

/**
 * Obfuscate a string by replacing the middle part with [..].
 *
 * @param {any} string String to obfuscate
 * @param {Number} obfuscation_factor Percentage of characters to leave intact at the beginning and end.
 *
 * @returns {String} Obfuscated string.
 */
function censor_string (string, obfuscation_factor) {
  const length = string.length;
  const leave_intact = Math.floor(length * obfuscation_factor / 2);
  // eslint-disable-next-line no-console
  console.assert(leave_intact > 0);

  const start = string.substr(0, leave_intact);
  const end = string.substr(string.length - leave_intact, string.length);
  const final = `${start}[..]${end}`;
  // eslint-disable-next-line no-console
  console.assert(final !== string, 'Failed to censor the string!');
  return final;
}

exports.censor_string = censor_string;

/**
 * mask passwords and private certificates in vcap while logging.
 * @param {String} vcaps
 * @returns {String} masked vcaps
 */
function mask_passwords_and_certificates_in_vcaps (vcaps) {
  const client_private_key_1_regexp = new RegExp('"client_authentication_private_key":.*', 'ig');
  const client_private_key_2_regexp = new RegExp('client_authentication_private_key:.*', 'ig');
  const client_id_1_regexp = new RegExp('clientid:.*', 'ig');
  const client_id_2_regexp = new RegExp('"clientid":.*', 'ig');
  const client_secret_1_regexp = new RegExp('clientsecret:.*', 'ig');
  const client_secret_2_regexp = new RegExp('"clientsecret":.*', 'ig');
  // eslint-disable-next-line no-control-regex
  const client_private_key_3_regexp = new RegExp('key:(.|\n)*', 'g');
  const client_private_key_4_regexp = new RegExp('.*-----BEGIN PRIVATE KEY.*END PRIVATE KEY.*', 'g');
  vcaps = vcaps.replace(/(P)ASSWORD.*/ig, '$1[...]');
  vcaps = vcaps.replace(client_private_key_1_regexp, '"client_authentication_private_key": [..]');
  vcaps = vcaps.replace(client_private_key_2_regexp, 'client_authentication_private_key: [..]');
  vcaps = vcaps.replace(client_id_1_regexp, 'clientid: [..]');
  vcaps = vcaps.replace(client_id_2_regexp, '"clientid": [..]');
  vcaps = vcaps.replace(client_secret_1_regexp, 'clientsecret: [..]');
  vcaps = vcaps.replace(client_secret_2_regexp, '"clientsecret": [..]');
  vcaps = vcaps.replace(client_private_key_3_regexp, 'key: [..]');
  vcaps = vcaps.replace(client_private_key_4_regexp, '');
  return vcaps;
}

exports.mask_passwords_and_certificates_in_vcaps = mask_passwords_and_certificates_in_vcaps;

const allowedPrivilegesInOnPremise = {
  'PSE': ['ALTER', 'REFERENCES'],
  'USERGROUP': ['USERGROUP OPERATOR'],
  'REMOTE SUBSCRIPTION': ['ALTER', 'PROCESS REMOTE SUBSCRIPTION EXCEPTION'],
  'AGENT': ['AGENT MESSAGING'],
  'REMOTE SOURCE': ['ALTER', 'CREATE REMOTE SUBSCRIPTION', 'CREATE VIRTUAL FUNCTION', 'CREATE VIRTUAL PROCEDURE', 'CREATE VIRTUAL TABLE', 'LINKED DATABASE', 'PROCESS REMOTE SUBSCRIPTION EXCEPTION', 'REMOTE EXECUTE', 'REMOTE TABLE ADMIN']
};
const allowedPrivilegesInCloud = {
  ...allowedPrivilegesInOnPremise,
  'JWT PROVIDER': ['ALTER', 'REFERENCES'],
  'SAML PROVIDER': ['ALTER', 'REFERENCES'],
  'X509 PROVIDER': ['ALTER', 'REFERENCES'],
  'ROLEGROUP': ['GRANTOR', 'OPERATOR'],
  'USERGROUP': ['GRANTOR', 'OPERATOR'],
};

/**
 * Validates the allowed global object privileges based on db type (on premise or cloud)
 * @param {Array} privileges privileges need to be granted
 * @param {String} type type of privileges
 * @param {String} obj name of object
 * @param {Boolean} ishanacloud is hana db or not
 */
function areAllowedGlobalObjectPrivileges (privileges, type, obj, ishanacloud) {
  const allowedPrivileges = ishanacloud ? allowedPrivilegesInCloud : allowedPrivilegesInOnPremise;
  if (allowedPrivileges.hasOwnProperty(type)) {
    for (let i =0;i<privileges.length;i++) {
      if (!allowedPrivileges[type].includes(privileges[i])) {
        throw new Error(`Invalid privilege ${privileges[i]}.\n${obj} of type ${type} is allowed to have only these privileges [${allowedPrivileges[type]}]`);
      }
    }
  } else {
    throw new Error(`Invalid object type ${type}.\nObject type must be one of the types in [${Object.keys(allowedPrivileges)}]`);
  }
}
exports.areAllowedGlobalObjectPrivileges = areAllowedGlobalObjectPrivileges;

/**
 * Generates current date and time
 *
 * @returns {String} current date and time.
 */

function currentDateTime () {
  const date_ob = new Date();
  const date = (`0${date_ob.getDate()}`).slice(-2);
  const month = (`0${date_ob.getMonth() + 1}`).slice(-2);
  const year = date_ob.getFullYear();
  let hours = date_ob.getHours();
  if (hours<=9)
    hours = `0${hours}`;
  let minutes = date_ob.getMinutes();
  if (minutes<=9)
    minutes = `0${minutes}`;
  let seconds = date_ob.getSeconds();
  if (seconds<=9)
    seconds = `0${seconds}`;
  const datetime = `${year}-${month}-${date} ${hours}:${minutes}:${seconds}`;
  return datetime;
}

exports.currentDateTime = currentDateTime;

function getUniqueAndDuplicatesByKey (inputArray, keyFunction) {
  const unique = [];
  const duplicated = [];
  const obj = {};
  inputArray.forEach(item => {
    const key = keyFunction(item);
    if (!obj[key]) {
      unique.push(item);
      obj[key] = item;
    } else  {
      duplicated.push(item);
    }
  });
  return [unique, duplicated];
}

exports.getUniqueAndDuplicatesByKey = getUniqueAndDuplicatesByKey;

/*
 * remove all the basic credentials which are already passed to hana_helper
 *
 * @param {Object} credentials object
 * @returns {Object} filtered credential object
 */
function removeManagedCredentials (credentials) {
  const remainingCredentialParameters = Object.assign({}, credentials);
  ['host', 'port', 'user', 'password', 'hdi_user', 'hdiUser', 'hdi_password', 'hdiPassword', 'certificate', 'db_hosts', 'hostname_in_certificate', 'validate_certificate', 'encrypt', 'client_authentication_private_key', 'client_authentication_certificate', 'accessRole', 'cdsAccessRole', 'schema', 'containerGroup', 'serviceInstanceId', 'id', 'tenant_id'].forEach(e => delete remainingCredentialParameters[e]);
  return remainingCredentialParameters;
}

exports.removeManagedCredentials = removeManagedCredentials;

function configureCertificateAuthentication (credentials, certs) {
  if (!certs) {
    return;
  }

  const startDelimiter = '-----BEGIN';
  certs.split(startDelimiter)
    .filter(cert => !!cert)
    .map(cert => `${startDelimiter} ${cert.replace(/\\n/g, '').trim()}`)
    .forEach(cert => {
      if (cert.includes(`${startDelimiter} CERTIFICATE`)) {
        if (credentials.client_authentication_certificate === undefined) {
          credentials.client_authentication_certificate = '';
        }
        credentials.client_authentication_certificate += cert;
        credentials.client_authentication_certificate += '\n';
      } else if (cert.includes(`${startDelimiter} PRIVATE KEY`)) {
        credentials.client_authentication_private_key = cert;
      }
    });
}

/**
 * Create a container object with the supplied credentials.
 *
 * @param {any} creds Credentials for the container.
 * @param {any} options Options, that can contain credentials as well.
 * @returns {Object} An object containing the credentials for a HANA / hdb connection.
 */
function prepareCredentials (creds, options, logger) {
  const other_parameters_in_creds = removeManagedCredentials(creds);
  const hdiCreds = {
    user: creds.hdi_user !== undefined ? creds.hdi_user : creds.user,
    password: creds.hdi_user !== undefined ? creds.hdi_password : creds.password
  };

  if (!hdiCreds.user && hdiCreds.password) {
    configureCertificateAuthentication(hdiCreds, hdiCreds.password);
  }

  if (creds.client_authentication_private_key) {
    hdiCreds.key = creds.client_authentication_private_key;
    logger.trace(`hdiCreds.key set to '${censor_string(hdiCreds.key, 0.05)}'`);
  }

  if (creds.client_authentication_certificate) {
    hdiCreds.cert = creds.client_authentication_certificate;
    logger.trace(`hdiCreds.cert set to '${hdiCreds.cert}'`);
  }

  if (Array.isArray(creds.db_hosts)) {
    hdiCreds.hosts = creds.db_hosts.map(entry => {
      if (entry.port) {
        entry.port = `${entry.port}`;
      }

      return entry;
    });
  } else {
    hdiCreds.host = creds.host;
    // hana-client@2.7.16 requires this to be a string.
    if (is_hdb_client) {
      hdiCreds.port = creds.port;
    } else {
      hdiCreds.port = `${creds.port}`;
    }
  }

  /**
   * custom logic to validate the server's hostname against the certificate
   * @param {string} hostname hostname for the connection
   * @param {Object} cert certificate
   * @returns
   */

  hdiCreds.checkServerIdentity = (hostname, cert) => {
    if (creds.sslValidateCertificate === false) {
      return undefined;
    }
    const host = creds.hostname_in_certificate ? creds.hostname_in_certificate : hostname;
    return tls.checkServerIdentity(host, cert);
  };

  if (creds.certificate) {
    hdiCreds.ca = Array.isArray(creds.certificate) ? creds.certificate : [creds.certificate];
    logger.trace('hdiCreds.ca set to', hdiCreds.ca);
  }

  if (creds.hostname_in_certificate) {
    hdiCreds.sslHostNameInCertificate = creds.hostname_in_certificate;
    logger.trace('hdiCreds.sslHostNameInCertificate set to', hdiCreds.sslHostNameInCertificate);
  }
  // boolean
  if (creds.validate_certificate !== undefined && creds.validate_certificate !== null) {
    hdiCreds.sslValidateCertificate = creds.validate_certificate;
    logger.trace('hdiCreds.sslValidateCertificate set to', hdiCreds.sslValidateCertificate);
  }
  // boolean
  if (creds.encrypt !== undefined && creds.encrypt !== null) {
    hdiCreds.encrypt = creds.encrypt;
    hdiCreds.useTLS = creds.encrypt;
    if (is_hdb_client) {
      logger.trace('hdiCreds.useTLS set to', hdiCreds.encrypt);
    } else {
      logger.trace('hdiCreds.encrypt set to', hdiCreds.encrypt);
    }
  }

  if (Object.keys(other_parameters_in_creds).length !== 0) {
    logger.trace('other parameters in hdicreds : ', other_parameters_in_creds);
    Object.assign(hdiCreds, other_parameters_in_creds);
  }

  hdiCreds.initializationTimeout = options.connectionTimeout;
  return hdiCreds;
}
exports.prepareCredentials = prepareCredentials;


/**
 * Calculate the SHA-256 hash of a readable stream.
 *
 * @param {ReadStream} readStream The readable stream to hash.
 * @param {Function} callback The callback function to call with the result or error.
 */
function calculateHashFromStream (readStream, callback) {
  const hash = crypto.createHash('sha256');
  readStream.on('data', (chunk) => {
    hash.update(chunk);
  });

  readStream.on('end', () => {
    const result = hash.digest('hex');
    callback(null, result);
  });

  readStream.on('error', (err) => {
    callback(err);
  });
}

exports.calculateHashFromStream = calculateHashFromStream;

function getDeployOrUndeployFiles (type, options, content) {
  let key;
  const {File} = require('@sap/hdi');
  if (type === 'deploy') {
    key = options.deploy;
  } else if (type === 'undeploy') {
    key = options.undeploy;
  }
  let files = [];
  files = Object.keys(key.files);
  if (key.regex.length > 0) {
    key.filter_by_regex(content.deployFiles.map((item) => item[0])).forEach((file) => files.push(file));
    files = [...new Set(files)];
  }
  if (type === 'deploy') {
    const {handle_client_files} = require('./hdi_utils.js');
    files = handle_client_files(files);
  }
  const deployOrUndeployFiles = files.filter((item) => !options.excludeFilter.matchesPath(item)).map((path) => new File(path));
  return deployOrUndeployFiles;
}
exports.getDeployOrUndeployFiles = getDeployOrUndeployFiles;


/**
 * Run the given $fn, expecting to call the $callback at the end. If execution is not done in $timeout milliseconds,
 * call the callback with an error - Timeout of $timeout reached.
 *
 * @param {Function} fn Function to call, taking callback as the first and only argument
 * @param {Function} callback Standard (error, result) callback
 * @param {Integer} timeout Timeout after which to call the callback with an error
 */
function callbackTimeout (fn, callback, timeout, timeoutName='Timeout') {
  let callbackCalled = false;
  let timeoutReached = false;

  const timer = setTimeout(() => {
    if (!callbackCalled) {
      timeoutReached = true;
      return callback(new Error(`${timeoutName} of ${timeout}ms reached!`));
    }
  }, timeout);

  fn((e, r) => {
    if (!timeoutReached) {
      clearTimeout(timer);
      callbackCalled = true;
      return callback(e, r);
    }
  });
}

exports.callbackTimeout = callbackTimeout;

/**
 * Writes items in batches with a timeout and error handling.
 * @param {Object} container - The HDI container instance with a .write method.
 * @param {Array} items - The items to write (folders and files with content).
 * @param {number} batchSize - The size of each batch.
 * @param {function} hdiCallback - Callback for HDI write (logger, cb, type)
 * @param {number} timeout - Timeout for each batch write.
 * @param {object} logger - Logger for logging.
 * @param {function} callback - Final callback when done or error.
 * @param {string} timeoutLabel - Label for timeout error messages.
 */
exports.writeBatchesWithTimeout = function (container, items, batchSize, hdiCallback, timeout, logger, callback, timeoutLabel) {
  const batches =  [];
  for (let i = 0; i < items.length; i += batchSize) {
    batches.push(items.slice(i, i + batchSize));
  }
  const shouldLogBatches = batches.length > 1;
  if (shouldLogBatches) {
    logger.log(`Writing ${items.length} items in ${batches.length} batches of size ${batchSize}`);
  } else {
    logger.log(`Writing ${items.length} items`);
  }
  async.eachSeries(
    batches,
    (batchItems, next) => {
      const batch = batchItems.map((file) => {
        if (typeof file[1] === 'function') {
          return new FileWithContent(file[0], file[1]());
        } else {
          return file;
        }
      });
      const batchIndex = batches.indexOf(batchItems);
      if (shouldLogBatches) {
        logger.log(`Writing batch ${batchIndex + 1} of ${batches.length}`);
      }
      callbackTimeout(
        (innerCb) => container.write(batch, null, innerCb),
        hdiCallback(logger, (err) => next(err), 'WRITE'),
        timeout,
        timeoutLabel
      );
    },
    callback
  );
};
